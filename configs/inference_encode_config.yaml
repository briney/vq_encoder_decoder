trained_model_dir: "path/to/trained_model"  # Directory where the trained model is saved
checkpoint_path: "checkpoints/best_valid.pth"
config_vqvae: "config_vqvae.yaml"
config_encoder: "config_gcpnet_encoder.yaml"
config_decoder: "config_geometric_decoder.yaml"

data_path: "path/to/inference/h5/data"
output_base_dir: "inference_encode_results"

batch_size: 16
shuffle: True
num_workers: 0
max_task_samples: 5000000
vq_indices_csv_filename: "vq_indices.csv"
mixed_precision: "bf16"  # no, fp16, bf16, fp8

tqdm_progress_bar: True

compile_model:
  enabled: False
  mode: null
  backend: inductor
  compile_encoder: True

# Streaming Parquet dataset (sharded) settings
# Results are written in chunks per rank to a Parquet dataset directory.
streaming_chunk_size: 10000           # rows per shard file before flushing to disk
parquet_compression: "zstd"           # "zstd" (recommended) or "snappy"
dataset_subdir: "parquet_dataset"     # subdirectory inside the timestamped result_dir

# Optional: merge all shards to a single Parquet file on main process only (out-of-core)
merge_to_single_parquet: false
final_parquet_filename: "vq_indices.parquet"
delete_shards_after_merge: false
